{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Simulación y extensión de un modelo de juegos evolutivos con cadenas de Markov en tiempo discreto**\n",
    "\n",
    "**Asignatura:** Cálculo estocástico (Grado en Ingeniería Matemática).  \n",
    "\n",
    "**Fecha de entrega:** viernes, 9 de mayo de 2025 a las 23:59.\n",
    "\n",
    "---\n",
    "\n",
    "### **Objetivo**  \n",
    "Replicar y extender el modelo de persistencia estratégica adaptativa presentado en el artículo proporcionado (Sección 2), incorporando un proceso estocástico basado en cadenas de Markov en tiempo discreto. Los estudiantes demostrarán su comprensión de:  \n",
    "1. Simulaciones de Monte Carlo en sistemas complejos.  \n",
    "2. Modelado de transiciones estratégicas mediante cadenas de Markov.  \n",
    "3. Análisis cuantitativo de dinámicas evolutivas en redes estructuradas.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Requisitos específicos**  \n",
    "**Parte 1: Replicación del modelo base**  \n",
    "1. Implementar en Python el modelo descrito en la Sección 2 del artículo, considerando:  \n",
    "   - Población en retículo cuadrado $ L \\times L $ ($ L = 100 $).  \n",
    "   - Mecanismo adaptativo de persistencia $\\tau_i(t)$ basado en la comparación $\\phi_i(t)$ vs. $\\varphi(t)$.  \n",
    "   - Actualización de estrategias mediante imitación probabilística (Ecuación 2 del paper).  \n",
    "   - Parámetros iniciales: $ b \\in [1, 1.6] $, $ K_1 = K_2 = 0.1 $, $\\Delta\\tau = 1$.  \n",
    "2. Validar la implementación reproduciendo la Figura 1 del artículo (fracción de cooperadores $ f_C $ vs. $ b $ para distintos $\\tau_U$).  \n",
    "\n",
    "**Parte 2: Extensión con cadenas de Markov**  \n",
    "Proponga y justifique una modificación al modelo original que integre **al menos un componente de cadena de Markov**. Algunas sugerencias:  \n",
    "- Definir estados de estrategia ($ C/D $) con matrices de transición dependientes de:  \n",
    "  - Entorno local ($\\phi_i$) y persistencia ($\\tau_i$).  \n",
    "  - Historial de pagos ($\\pi_i(t)$) o tiempo en la estrategia actual ($\\ell_i$).  \n",
    "- Introducir un proceso de Markov oculto que module $\\tau_i(t)$.  \n",
    "- Modelar la influencia de vecinos como transiciones entre estados.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Instrucciones detalladas**  \n",
    "1. **Código Python**:  \n",
    "   - Usar librerías científicas (numpy, matplotlib, networkx).  \n",
    "   - Incluir comentarios que expliquen:  \n",
    "     - Estructura de datos para almacenar $\\tau_i(t)$, $\\ell_i$, y estados.  \n",
    "     - Lógica de actualización de estrategias y persistencia.  \n",
    "     - Implementación de la cadena de Markov propuesta.  \n",
    "   - Optimizar el código para ejecuciones eficientes ($ L = 100 $, 1000 pasos MC).  \n",
    "\n",
    "2. **Experimentos y análisis**:  \n",
    "   - Para $ b = 1.1 $ y $\\tau_U = 20 $, compare:  \n",
    "     - Tiempo de convergencia al estado estacionario (modelo base vs. extensión Markoviana).  \n",
    "     - Distribución estacionaria de $\\tau_i$ para cooperadores/desertores.  \n",
    "   - Analice cómo la cadena de Markov afecta:  \n",
    "     - La formación de clusters cooperativos.  \n",
    "     - La robustez ante fluctuaciones ($ K_1 \\in \\{0.1, 1, 10\\} $).  \n",
    "\n",
    "3. **Reporte técnico**:  \n",
    "   - Sección de metodología: Descripción matemática de la cadena de Markov incorporada.  \n",
    "   - Visualizaciones:  \n",
    "     - Diagrama de estados de la cadena propuesta.  \n",
    "     - Heatmaps de $ f_C $ vs. $ b $ y parámetros de la cadena.  \n",
    "   - Discusión crítica: Ventajas/limitaciones del enfoque Markoviano vs. el modelo original.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Sugerencias de enfoque**  \n",
    "- Para la matriz de transición, considere funciones basadas en Fermi-Dirac o logísticas que vinculen $\\phi_i(t)$, $\\varphi(t)$, y $\\tau_i(t)$.  \n",
    "- Ejemplo de transición Markoviana:  \n",
    "  $$\n",
    "  P_{CD}(t) = \\frac{1}{1 + e^{-(\\alpha \\cdot \\phi_i(t) - \\beta \\cdot \\varphi(t))/K}}\n",
    "  $$\n",
    "  donde $\\alpha$ y $\\beta$ ponderan la influencia local vs. global.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Entrega:**  \n",
    "- Se deberá entregar un archivo de Jupyter Notebook (.ipynb) con las simulaciones e incluyendo gráficos y conclusiones.  \n",
    "\n",
    "**Nota:** Se valorará especialmente la justificación teórica de la cadena de Markov y su impacto en la dinámica cooperativa.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
